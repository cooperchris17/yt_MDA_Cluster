{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook shows the highest accuracy for Support Vector Machines (A1, A2, B1, B2+)\n",
    "(MLP Classifier was more accurate than SVM when I resampled 250 texts in the training set for each class, but that is in a different notebook)\n",
    "\n",
    "##### Bootstrapping \n",
    "- with 500 texts in each class in the training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>cefr</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A1Movers_1_1</td>\n",
       "      <td>Look, Grandpa. My friend's family are in the g...</td>\n",
       "      <td>A1</td>\n",
       "      <td>[0.010332267731428146, -0.0009531814139336348,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A1Movers_1_2</td>\n",
       "      <td>Come quickly, children. The train's waiting to...</td>\n",
       "      <td>A1</td>\n",
       "      <td>[0.002182072727009654, -6.590186239918694e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A1Movers_1_3</td>\n",
       "      <td>Hello, Mrs Castle. Hello Sally, Oh I'm tired. ...</td>\n",
       "      <td>A1</td>\n",
       "      <td>[-0.00018498786084819585, 0.013357731513679028...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A1Movers_1_4</td>\n",
       "      <td>Dad, come and watch this DVD with me. What's i...</td>\n",
       "      <td>A1</td>\n",
       "      <td>[0.017183320596814156, -0.00948919914662838, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A1Movers_1_5</td>\n",
       "      <td>Can you colour this mountain picture now? Yes!...</td>\n",
       "      <td>A1</td>\n",
       "      <td>[0.01187464315444231, 0.009958968497812748, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>723</td>\n",
       "      <td>C2Prof_16-20</td>\n",
       "      <td>Today, we're talking to marine biologists Gina...</td>\n",
       "      <td>B2</td>\n",
       "      <td>[0.0013554414035752416, -0.0029449746944010258...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>724</td>\n",
       "      <td>C2Prof_21-30</td>\n",
       "      <td>I knew I'd be short of money if I didn't work ...</td>\n",
       "      <td>B2</td>\n",
       "      <td>[-0.007415663916617632, -0.02614154852926731, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>725</td>\n",
       "      <td>C2Prof_3-4</td>\n",
       "      <td>Last year, Tim Fitzgerald exhibited photograph...</td>\n",
       "      <td>B2</td>\n",
       "      <td>[-0.009252717718482018, 0.008551654405891895, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>726</td>\n",
       "      <td>C2Prof_5-6</td>\n",
       "      <td>One of my own thoughts about this piece is the...</td>\n",
       "      <td>B2</td>\n",
       "      <td>[-0.02017894573509693, -0.001436770660802722, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>727</td>\n",
       "      <td>C2Prof_7-15</td>\n",
       "      <td>I want to talk to you today about a spice whic...</td>\n",
       "      <td>B2</td>\n",
       "      <td>[0.004746410064399242, 0.020655736327171326, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>728 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0      filename  \\\n",
       "0             0  A1Movers_1_1   \n",
       "1             1  A1Movers_1_2   \n",
       "2             2  A1Movers_1_3   \n",
       "3             3  A1Movers_1_4   \n",
       "4             4  A1Movers_1_5   \n",
       "..          ...           ...   \n",
       "723         723  C2Prof_16-20   \n",
       "724         724  C2Prof_21-30   \n",
       "725         725    C2Prof_3-4   \n",
       "726         726    C2Prof_5-6   \n",
       "727         727   C2Prof_7-15   \n",
       "\n",
       "                                                  text cefr  \\\n",
       "0    Look, Grandpa. My friend's family are in the g...   A1   \n",
       "1    Come quickly, children. The train's waiting to...   A1   \n",
       "2    Hello, Mrs Castle. Hello Sally, Oh I'm tired. ...   A1   \n",
       "3    Dad, come and watch this DVD with me. What's i...   A1   \n",
       "4    Can you colour this mountain picture now? Yes!...   A1   \n",
       "..                                                 ...  ...   \n",
       "723  Today, we're talking to marine biologists Gina...   B2   \n",
       "724  I knew I'd be short of money if I didn't work ...   B2   \n",
       "725  Last year, Tim Fitzgerald exhibited photograph...   B2   \n",
       "726  One of my own thoughts about this piece is the...   B2   \n",
       "727  I want to talk to you today about a spice whic...   B2   \n",
       "\n",
       "                                             embedding  \n",
       "0    [0.010332267731428146, -0.0009531814139336348,...  \n",
       "1    [0.002182072727009654, -6.590186239918694e-05,...  \n",
       "2    [-0.00018498786084819585, 0.013357731513679028...  \n",
       "3    [0.017183320596814156, -0.00948919914662838, 0...  \n",
       "4    [0.01187464315444231, 0.009958968497812748, 0....  \n",
       "..                                                 ...  \n",
       "723  [0.0013554414035752416, -0.0029449746944010258...  \n",
       "724  [-0.007415663916617632, -0.02614154852926731, ...  \n",
       "725  [-0.009252717718482018, 0.008551654405891895, ...  \n",
       "726  [-0.02017894573509693, -0.001436770660802722, ...  \n",
       "727  [0.004746410064399242, 0.020655736327171326, 0...  \n",
       "\n",
       "[728 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# load data\n",
    "datafile_path = \"bc_cam_with_ada_002_embeddings.csv\"\n",
    "\n",
    "df = pd.read_csv(datafile_path)\n",
    "# convert all C level labels to B2\n",
    "df['cefr'] = df['cefr'].replace({'C': 'B2'})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I adapted the code, so the texts in the training set could be bootstrapped (using resample in sklearn)\n",
    "- maybe this code is not DRY (I think there are 1 or 2 uneccesary steps and it could be cleaner, but it works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Use ast.literal_eval to safely evaluate the string and convert it into a list\n",
    "df['embedding'] = df['embedding'].apply(ast.literal_eval)\n",
    "\n",
    "# create a column for each embedding\n",
    "df_embeddings = pd.DataFrame(df['embedding'].to_list(), columns=[f'embed_{i}' for i in range(len(df['embedding'][0]))])\n",
    "\n",
    "# Add the labels back\n",
    "df_embeddings = pd.concat([df_embeddings, df[\"cefr\"]], axis=1)\n",
    "\n",
    "# split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_embeddings.drop('cefr', axis=1), df_embeddings['cefr'], test_size=0.2, random_state=160923\n",
    ")\n",
    "\n",
    "# Convert the training set lists to a DataFrame\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Separate the classes in the training set\n",
    "class_A1 = df_train[df_train['cefr'] == \"A1\"]\n",
    "class_A2 = df_train[df_train['cefr'] == \"A2\"]\n",
    "class_B1 = df_train[df_train['cefr'] == \"B1\"]\n",
    "class_B2 = df_train[df_train['cefr'] == \"B2\"]\n",
    "\n",
    "# Bootstrap each class in the training set to have 500 samples\n",
    "class_A1_sampled = resample(class_A1, replace=True, n_samples=500, random_state=160923)\n",
    "class_A2_sampled = resample(class_A2, replace=True, n_samples=500, random_state=160923)\n",
    "class_B1_sampled = resample(class_B1, replace=True, n_samples=500, random_state=160923)\n",
    "class_B2_sampled = resample(class_B2, replace=True, n_samples=500, random_state=160923)\n",
    "\n",
    "# Concatenate the bootstrapped classes back together\n",
    "df_train_sampled = pd.concat([class_A1_sampled, class_A2_sampled, class_B1_sampled, class_B2_sampled])\n",
    "\n",
    "# Now can use df_train_sampled for machine learning tasks\n",
    "X_train_sampled = df_train_sampled.drop('cefr', axis=1)\n",
    "y_train_sampled = df_train_sampled.cefr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.64      0.88      0.74         8\n",
      "          A2       0.59      0.77      0.67        13\n",
      "          B1       0.79      0.68      0.73        44\n",
      "          B2       0.86      0.85      0.86        81\n",
      "\n",
      "    accuracy                           0.79       146\n",
      "   macro avg       0.72      0.79      0.75       146\n",
      "weighted avg       0.80      0.79      0.80       146\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 7  1  0  0]\n",
      " [ 2 10  1  0]\n",
      " [ 1  2 30 11]\n",
      " [ 1  4  7 69]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# train SVM classifier\n",
    "# the default kernel is rbf (gaussian)\n",
    "clf = svm.SVC(probability=True)\n",
    "clf.fit(X_train_sampled, y_train_sampled)\n",
    "preds = clf.predict(X_test)\n",
    "probas = clf.predict_proba(X_test)\n",
    "\n",
    "report = classification_report(y_test, preds)\n",
    "print(report)\n",
    "\n",
    "# print confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.64      0.88      0.74         8\n",
      "          A2       0.56      0.77      0.65        13\n",
      "          B1       0.76      0.66      0.71        44\n",
      "          B2       0.86      0.84      0.85        81\n",
      "\n",
      "    accuracy                           0.78       146\n",
      "   macro avg       0.70      0.79      0.73       146\n",
      "weighted avg       0.79      0.78      0.78       146\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 7  1  0  0]\n",
      " [ 2 10  1  0]\n",
      " [ 1  3 29 11]\n",
      " [ 1  4  8 68]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# train SVM classifier\n",
    "# the default kernel is rbf (gaussian)\n",
    "clf = svm.SVC(kernel='linear', probability=True)\n",
    "clf.fit(X_train_sampled, y_train_sampled)\n",
    "preds = clf.predict(X_test)\n",
    "probas = clf.predict_proba(X_test)\n",
    "\n",
    "report = classification_report(y_test, preds)\n",
    "print(report)\n",
    "\n",
    "# print confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial\n",
    "- this seemed to be the most accurate kernel (slightly higher than the default rbf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.64      0.88      0.74         8\n",
      "          A2       0.59      0.77      0.67        13\n",
      "          B1       0.89      0.70      0.78        44\n",
      "          B2       0.88      0.90      0.89        81\n",
      "\n",
      "    accuracy                           0.83       146\n",
      "   macro avg       0.75      0.81      0.77       146\n",
      "weighted avg       0.84      0.83      0.83       146\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 7  1  0  0]\n",
      " [ 2 10  1  0]\n",
      " [ 1  2 31 10]\n",
      " [ 1  4  3 73]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# train SVM classifier\n",
    "# the default kernel is rbf (gaussian)\n",
    "clf = svm.SVC(kernel='poly', probability=True)\n",
    "clf.fit(X_train_sampled, y_train_sampled)\n",
    "preds = clf.predict(X_test)\n",
    "probas = clf.predict_proba(X_test)\n",
    "\n",
    "report = classification_report(y_test, preds)\n",
    "print(report)\n",
    "\n",
    "# print confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.60      0.75      0.67         8\n",
      "          A2       0.50      0.77      0.61        13\n",
      "          B1       0.71      0.57      0.63        44\n",
      "          B2       0.83      0.83      0.83        81\n",
      "\n",
      "    accuracy                           0.74       146\n",
      "   macro avg       0.66      0.73      0.68       146\n",
      "weighted avg       0.75      0.74      0.74       146\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 6  2  0  0]\n",
      " [ 2 10  1  0]\n",
      " [ 1  4 25 14]\n",
      " [ 1  4  9 67]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# train SVM classifier\n",
    "# the default kernel is rbf (gaussian)\n",
    "clf = svm.SVC(kernel='sigmoid', probability=True)\n",
    "clf.fit(X_train_sampled, y_train_sampled)\n",
    "preds = clf.predict(X_test)\n",
    "probas = clf.predict_proba(X_test)\n",
    "\n",
    "report = classification_report(y_test, preds)\n",
    "print(report)\n",
    "\n",
    "# print confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nromalize the data\n",
    "- accuracy got worse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.67      0.25      0.36         8\n",
      "          A2       0.57      0.31      0.40        13\n",
      "          B1       0.67      0.66      0.67        44\n",
      "          B2       0.80      0.91      0.85        81\n",
      "\n",
      "    accuracy                           0.75       146\n",
      "   macro avg       0.68      0.53      0.57       146\n",
      "weighted avg       0.73      0.75      0.73       146\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2  0  4  2]\n",
      " [ 1  4  5  3]\n",
      " [ 0  1 29 14]\n",
      " [ 0  2  5 74]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# train SVM classifier\n",
    "# I'm using poly because it was the most accurate \n",
    "clf = make_pipeline(StandardScaler(), SVC(kernel='poly', probability=True))\n",
    "clf.fit(X_train_sampled, y_train_sampled)\n",
    "preds = clf.predict(X_test)\n",
    "probas = clf.predict_proba(X_test)\n",
    "\n",
    "report = classification_report(y_test, preds)\n",
    "print(report)\n",
    "\n",
    "# print confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try MinMaxScaler\n",
    "- macro avg 1% lower, but it seems to be overall more accurate across the classes\n",
    "\n",
    "# This is the model that I chose due to the accuracy across the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.64      0.88      0.74         8\n",
      "          A2       0.75      0.69      0.72        13\n",
      "          B1       0.76      0.66      0.71        44\n",
      "          B2       0.86      0.90      0.88        81\n",
      "\n",
      "    accuracy                           0.81       146\n",
      "   macro avg       0.75      0.78      0.76       146\n",
      "weighted avg       0.81      0.81      0.81       146\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 7  1  0  0]\n",
      " [ 2  9  2  0]\n",
      " [ 1  2 29 12]\n",
      " [ 1  0  7 73]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# train SVM classifier\n",
    "# I'm using poly because it was the most accurate \n",
    "clf = make_pipeline(MinMaxScaler(), SVC(kernel='poly', probability=True))\n",
    "clf.fit(X_train_sampled, y_train_sampled)\n",
    "preds = clf.predict(X_test)\n",
    "probas = clf.predict_proba(X_test)\n",
    "\n",
    "report = classification_report(y_test, preds)\n",
    "print(report)\n",
    "\n",
    "# print confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try change the c value\n",
    "- doesn't seem to change much, but maybe I can try and write a loop like the R book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.64      0.88      0.74         8\n",
      "          A2       0.59      0.77      0.67        13\n",
      "          B1       0.89      0.70      0.78        44\n",
      "          B2       0.88      0.90      0.89        81\n",
      "\n",
      "    accuracy                           0.83       146\n",
      "   macro avg       0.75      0.81      0.77       146\n",
      "weighted avg       0.84      0.83      0.83       146\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 7  1  0  0]\n",
      " [ 2 10  1  0]\n",
      " [ 1  2 31 10]\n",
      " [ 1  4  3 73]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# train SVM classifier\n",
    "clf = svm.SVC(C=1, kernel='poly', probability=True)\n",
    "clf.fit(X_train_sampled, y_train_sampled)\n",
    "preds = clf.predict(X_test)\n",
    "probas = clf.predict_proba(X_test)\n",
    "\n",
    "report = classification_report(y_test, preds)\n",
    "print(report)\n",
    "\n",
    "# print confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try changing the C value with scaled data\n",
    "- doesn't seem to do much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.64      0.88      0.74         8\n",
      "          A2       0.75      0.69      0.72        13\n",
      "          B1       0.76      0.66      0.71        44\n",
      "          B2       0.86      0.90      0.88        81\n",
      "\n",
      "    accuracy                           0.81       146\n",
      "   macro avg       0.75      0.78      0.76       146\n",
      "weighted avg       0.81      0.81      0.81       146\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 7  1  0  0]\n",
      " [ 2  9  2  0]\n",
      " [ 1  2 29 12]\n",
      " [ 1  0  7 73]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# train SVM classifier\n",
    "# I'm using poly because it was the most accurate \n",
    "clf = make_pipeline(MinMaxScaler(), SVC(C=0.8, kernel='poly', probability=True))\n",
    "clf.fit(X_train_sampled, y_train_sampled)\n",
    "preds = clf.predict(X_test)\n",
    "probas = clf.predict_proba(X_test)\n",
    "\n",
    "report = classification_report(y_test, preds)\n",
    "print(report)\n",
    "\n",
    "# print confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R Function (if I want to try to adapt to find c value)\n",
    "- it doesn't seem to make much difference though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_values <- c(1, seq(from = 5, to = 40, by = 5))\n",
    "\n",
    "accuracy_values <- sapply(cost_values, function(x) {\n",
    "  set.seed(12345)\n",
    "  m <- ksvm(letter ~ ., data = letters_train,\n",
    "            kernel = \"rbfdot\", C = x)\n",
    "  pred <- predict(m, letters_test)\n",
    "  agree <- ifelse(pred == letters_test$letter, 1, 0)\n",
    "  accuracy <- sum(agree) / nrow(letters_test)\n",
    "  return (accuracy)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cefr-venv",
   "language": "python",
   "name": "cefr-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "365536dcbde60510dc9073d6b991cd35db2d9bac356a11f5b64279a5e6708b97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
